{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(830, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bi-rads</th>\n",
       "      <th>age</th>\n",
       "      <th>shape</th>\n",
       "      <th>margin</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bi-rads  age  shape  margin  density\n",
       "0          5   67      3       5        3\n",
       "2          5   58      4       5        3\n",
       "3          4   28      1       1        3\n",
       "8          5   57      1       5        3\n",
       "10         5   76      1       4        3\n",
       "..       ...  ...    ...     ...      ...\n",
       "949        4   47      2       1        3\n",
       "950        4   56      4       5        3\n",
       "951        4   64      4       5        3\n",
       "952        5   66      4       5        3\n",
       "953        4   62      3       3        3\n",
       "\n",
       "[830 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"mammographic_masses.data\",names=[\"bi-rads\",\"age\",\"shape\",\"margin\",\"density\",\"severity\"])\n",
    "data_n=data.values #extracting only the matrix of values \n",
    "\n",
    "data = data[(data['bi-rads']!='?') & (data['age']!='?') & (data['shape']!='?') & (data['margin']!='?') & (data['density']!='?') & (data['severity']!='?')]\n",
    "data = data.astype(int)\n",
    "print(data.shape)\n",
    "\n",
    "X = data[[\"bi-rads\",\"age\",\"shape\",\"margin\",\"density\"]]\n",
    "y=data[[\"severity\"]].values\n",
    "X\n",
    "\n",
    "##a few examples from the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4\n",
       "0    0  0  1  0\n",
       "2    0  0  0  1\n",
       "3    1  0  0  0\n",
       "8    1  0  0  0\n",
       "10   1  0  0  0\n",
       "..  .. .. .. ..\n",
       "949  0  1  0  0\n",
       "950  0  0  0  1\n",
       "951  0  0  0  1\n",
       "952  0  0  0  1\n",
       "953  0  0  1  0\n",
       "\n",
       "[830 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_shapes = pd.get_dummies(X['shape'])\n",
    "one_hot_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_one_hot = X.join(one_hot_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bi-rads</th>\n",
       "      <th>age</th>\n",
       "      <th>margin</th>\n",
       "      <th>density</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bi-rads  age  margin  density  1  2  3  4\n",
       "0          5   67       5        3  0  0  1  0\n",
       "2          5   58       5        3  0  0  0  1\n",
       "3          4   28       1        3  1  0  0  0\n",
       "8          5   57       5        3  1  0  0  0\n",
       "10         5   76       4        3  1  0  0  0\n",
       "..       ...  ...     ...      ... .. .. .. ..\n",
       "949        4   47       1        3  0  1  0  0\n",
       "950        4   56       5        3  0  0  0  1\n",
       "951        4   64       5        3  0  0  0  1\n",
       "952        5   66       5        3  0  0  0  1\n",
       "953        4   62       3        3  0  0  1  0\n",
       "\n",
       "[830 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_one_hot.drop('shape', axis=1, inplace=True)\n",
    "X_one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bi-rads</th>\n",
       "      <th>age</th>\n",
       "      <th>margin</th>\n",
       "      <th>density</th>\n",
       "      <th>round</th>\n",
       "      <th>oval</th>\n",
       "      <th>lobular</th>\n",
       "      <th>irregular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bi-rads  age  margin  density  round  oval  lobular  irregular\n",
       "0          5   67       5        3      0     0        1          0\n",
       "2          5   58       5        3      0     0        0          1\n",
       "3          4   28       1        3      1     0        0          0\n",
       "8          5   57       5        3      1     0        0          0\n",
       "10         5   76       4        3      1     0        0          0\n",
       "..       ...  ...     ...      ...    ...   ...      ...        ...\n",
       "949        4   47       1        3      0     1        0          0\n",
       "950        4   56       5        3      0     0        0          1\n",
       "951        4   64       5        3      0     0        0          1\n",
       "952        5   66       5        3      0     0        0          1\n",
       "953        4   62       3        3      0     0        1          0\n",
       "\n",
       "[830 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_one_hot.rename(columns={1: 'round', 2: 'oval',\n",
    "                 3: 'lobular', 4: 'irregular'}, inplace=True)\n",
    "X_one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4  5\n",
       "0    0  0  0  0  1\n",
       "2    0  0  0  0  1\n",
       "3    1  0  0  0  0\n",
       "8    0  0  0  0  1\n",
       "10   0  0  0  1  0\n",
       "..  .. .. .. .. ..\n",
       "949  1  0  0  0  0\n",
       "950  0  0  0  0  1\n",
       "951  0  0  0  0  1\n",
       "952  0  0  0  0  1\n",
       "953  0  0  1  0  0\n",
       "\n",
       "[830 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_margin = pd.get_dummies(X['margin'])\n",
    "one_hot_margin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_one_hot = X_one_hot.join(one_hot_margin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bi-rads</th>\n",
       "      <th>age</th>\n",
       "      <th>density</th>\n",
       "      <th>round</th>\n",
       "      <th>oval</th>\n",
       "      <th>lobular</th>\n",
       "      <th>irregular</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bi-rads  age  density  round  oval  lobular  irregular  1  2  3  4  5\n",
       "0          5   67        3      0     0        1          0  0  0  0  0  1\n",
       "2          5   58        3      0     0        0          1  0  0  0  0  1\n",
       "3          4   28        3      1     0        0          0  1  0  0  0  0\n",
       "8          5   57        3      1     0        0          0  0  0  0  0  1\n",
       "10         5   76        3      1     0        0          0  0  0  0  1  0\n",
       "..       ...  ...      ...    ...   ...      ...        ... .. .. .. .. ..\n",
       "949        4   47        3      0     1        0          0  1  0  0  0  0\n",
       "950        4   56        3      0     0        0          1  0  0  0  0  1\n",
       "951        4   64        3      0     0        0          1  0  0  0  0  1\n",
       "952        5   66        3      0     0        0          1  0  0  0  0  1\n",
       "953        4   62        3      0     0        1          0  0  0  1  0  0\n",
       "\n",
       "[830 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_one_hot.drop('margin', axis=1, inplace=True)\n",
    "X_one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bi-rads</th>\n",
       "      <th>age</th>\n",
       "      <th>density</th>\n",
       "      <th>round</th>\n",
       "      <th>oval</th>\n",
       "      <th>lobular</th>\n",
       "      <th>irregular</th>\n",
       "      <th>circumscribed</th>\n",
       "      <th>microlobulated</th>\n",
       "      <th>obscured</th>\n",
       "      <th>ill-defined</th>\n",
       "      <th>spiculated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bi-rads  age  density  round  oval  lobular  irregular  circumscribed  \\\n",
       "0          5   67        3      0     0        1          0              0   \n",
       "2          5   58        3      0     0        0          1              0   \n",
       "3          4   28        3      1     0        0          0              1   \n",
       "8          5   57        3      1     0        0          0              0   \n",
       "10         5   76        3      1     0        0          0              0   \n",
       "..       ...  ...      ...    ...   ...      ...        ...            ...   \n",
       "949        4   47        3      0     1        0          0              1   \n",
       "950        4   56        3      0     0        0          1              0   \n",
       "951        4   64        3      0     0        0          1              0   \n",
       "952        5   66        3      0     0        0          1              0   \n",
       "953        4   62        3      0     0        1          0              0   \n",
       "\n",
       "     microlobulated  obscured  ill-defined  spiculated  \n",
       "0                 0         0            0           1  \n",
       "2                 0         0            0           1  \n",
       "3                 0         0            0           0  \n",
       "8                 0         0            0           1  \n",
       "10                0         0            1           0  \n",
       "..              ...       ...          ...         ...  \n",
       "949               0         0            0           0  \n",
       "950               0         0            0           1  \n",
       "951               0         0            0           1  \n",
       "952               0         0            0           1  \n",
       "953               0         1            0           0  \n",
       "\n",
       "[830 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_one_hot.rename(columns={1: 'circumscribed', 2: 'microlobulated',\n",
    "                 3: 'obscured', 4: 'ill-defined', 5: 'spiculated'}, inplace=True)\n",
    "X_one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % of the cases marked with Bi-Rads = 1 are positive\n",
      "0.0 % of the cases marked with Bi-Rads = 2 are positive\n",
      "16.67 % of the cases marked with Bi-Rads = 3 are positive\n",
      "22.01 % of the cases marked with Bi-Rads = 4 are positive\n",
      "90.22 % of the cases marked with Bi-Rads = 5 are positive\n"
     ]
    }
   ],
   "source": [
    "SeverityBR= pd.DataFrame({\"bi-rads\":data[\"bi-rads\"], \"severity\":data[\"severity\"]})\n",
    "\n",
    "BiRads=[1,2,3,4,5]\n",
    "\n",
    "for n in BiRads:\n",
    "    SBRnumber=SeverityBR[SeverityBR[\"bi-rads\"]== n]\n",
    "    l=len(SBRnumber)\n",
    "    Positive=len(SBRnumber[SBRnumber[\"severity\"] == 1])\n",
    "    Negative=len(SBRnumber[SBRnumber[\"severity\"] == 0])\n",
    "    if l== 0:\n",
    "        print(0.0, f'% of the cases marked with Bi-Rads = {n} are positive')\n",
    "    else:\n",
    "        print(round(((Positive/l)*100),2), f'% of the cases marked with Bi-Rads = {n} are positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(data,diag_kind=\"kde\",hue=\"severity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = sklearn.preprocessing.PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = sklearn.preprocessing.normalize(X)\n",
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "c = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "l1 = np.arange(0.2, 0.9, 0.1)\n",
    "\n",
    "param_grid = {\n",
    "    'C': c,\n",
    "    'solver': ['saga'],\n",
    "    'penalty': ['elasticnet'],\n",
    "    'l1_ratio': l1\n",
    "}\n",
    "\n",
    "param_grid_2 = {\n",
    "    'C': c,\n",
    "    'penalty': ['none', 'l2'],\n",
    "}\n",
    "\n",
    "param_grid_3 = {\n",
    "    'C': c,\n",
    "    'solver': ['liblinear'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "i = 1\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=i)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=i)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_one_hot, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf_1 = GridSearchCV(estimator=LogisticRegression(max_iter=5000), param_grid=param_grid, cv=inner_cv, scoring='recall')\n",
    "#nested_score_1 = cross_val_score(clf_1, X=X, y=y.ravel(), cv=outer_cv)\n",
    "#nested_score_1.mean()\n",
    "clf_1.fit(X_train, y_train.ravel())\n",
    "y_pred_1 = clf_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf_2 = GridSearchCV(estimator=LogisticRegression(\n",
    "    max_iter=5000), param_grid=param_grid_2, cv=inner_cv, scoring='recall')\n",
    "#nested_score_2 = cross_val_score(clf_2, X=X, y=y.ravel(), cv=outer_cv)\n",
    "#nested_score_2.mean()\n",
    "clf_2.fit(X_train, y_train.ravel())\n",
    "y_pred_2 = clf_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_3 = GridSearchCV(estimator=LogisticRegression(),\n",
    "                     param_grid=param_grid_3, cv=inner_cv, scoring='recall')\n",
    "#nested_score_3 = cross_val_score(clf_3, X=X, y=y.ravel(), cv=outer_cv)\n",
    "#nested_score_3.mean()\n",
    "clf_3.fit(X_train, y_train.ravel())\n",
    "y_pred_3 = clf_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Clf_1 #####\n",
      "Accuracy:  0.8514056224899599\n",
      "Recall:  0.8852459016393442\n",
      "F1:  0.8537549407114624\n",
      "0.8244274809160306\n",
      "Confusion Matrix: \n",
      " [[104  23]\n",
      " [ 14 108]]\n"
     ]
    }
   ],
   "source": [
    "print(\"##### Clf_1 #####\")\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred_1))\n",
    "print(\"Recall: \", metrics.recall_score(y_test, y_pred_1))\n",
    "print(\"Precision: \", metrics.precision_score(y_test, y_pred_1))\n",
    "print(\"F1: \", metrics.f1_score(y_test, y_pred_1))\n",
    "print(\"Confusion Matrix: \\n\", metrics.confusion_matrix(y_test, y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Clf_2 #####\n",
      "Accuracy:  0.8554216867469879\n",
      "Recall:  0.8688524590163934\n",
      "F1:  0.8548387096774194\n",
      "0.8412698412698413\n",
      "Confusion Matrix: \n",
      " [[107  20]\n",
      " [ 16 106]]\n"
     ]
    }
   ],
   "source": [
    "print(\"##### Clf_2 #####\")\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred_2))\n",
    "print(\"Recall: \", metrics.recall_score(y_test, y_pred_2))\n",
    "print(\"Precision: \", metrics.precision_score(y_test, y_pred_2))\n",
    "print(\"F1: \", metrics.f1_score(y_test, y_pred_2))\n",
    "print(\"Confusion Matrix: \\n\", metrics.confusion_matrix(y_test, y_pred_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Clf_3 #####\n",
      "Accuracy:  0.8554216867469879\n",
      "Recall:  0.8688524590163934\n",
      "F1:  0.8548387096774194\n",
      "Confusion Matrix: \n",
      " [[107  20]\n",
      " [ 16 106]]\n"
     ]
    }
   ],
   "source": [
    "print(\"##### Clf_3 #####\")\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred_3))\n",
    "print(\"Recall: \", metrics.recall_score(y_test, y_pred_3))\n",
    "print(\"Precision: \", metrics.precision_score(y_test, y_pred_3))\n",
    "print(\"F1: \", metrics.f1_score(y_test, y_pred_3))\n",
    "print(\"Confusion Matrix: \\n\", metrics.confusion_matrix(y_test, y_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set 1:\n",
      "{'C': 0.0001, 'l1_ratio': 0.6000000000000001, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "1.0\n",
      "\n",
      "Best parameters set found on development set 2:\n",
      "{'C': 0.1, 'penalty': 'l2'}\n",
      "0.7998091493100568\n",
      "\n",
      "Best parameters set found on development set 3:\n",
      "{'C': 0.0001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set 1:\")\n",
    "print(clf_1.best_params_) \n",
    "print(clf_1.best_score_)\n",
    "\n",
    "print(\"\\nBest parameters set found on development set 2:\")\n",
    "print(clf_2.best_params_)\n",
    "print(clf_2.best_score_)\n",
    "\n",
    "print(\"\\nBest parameters set found on development set 3:\")\n",
    "print(clf_3.best_params_)\n",
    "print(clf_3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Clf Final#####\n",
      "Accuracy:  0.8433734939759037\n",
      "Recall:  0.9180327868852459\n",
      "Precision:  0.7943262411347518\n",
      "F1:  0.8517110266159698\n",
      "Confusion Matrix: \n",
      " [[ 98  29]\n",
      " [ 10 112]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_one_hot, y, test_size=0.3, random_state=42)\n",
    "clf = LogisticRegression(C=0.1, penalty='elasticnet', solver='saga', l1_ratio=0.4)\n",
    "clf.fit(X_train, y_train.ravel())\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"##### Clf Final#####\")\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Recall: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"Precision: \", metrics.precision_score(y_test, y_pred))\n",
    "print(\"F1: \", metrics.f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \\n\", metrics.confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Clf Original #####\n",
      "Accuracy:  0.8032128514056225\n",
      "Recall:  0.9016393442622951\n",
      "Precision:  0.7482993197278912\n",
      "F1:  0.8178438661710038\n",
      "Confusion Matrix: \n",
      " [[ 90  37]\n",
      " [ 12 110]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(C=0.1, penalty='elasticnet', solver='saga', l1_ratio=0.7)\n",
    "clf.fit(X_train, y_train.ravel())\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"##### Clf Original #####\")\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Recall: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"Precision: \", metrics.precision_score(y_test, y_pred))\n",
    "print(\"F1: \", metrics.f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \\n\", metrics.confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Clf Poly #####\n",
      "Accuracy:  0.8514056224899599\n",
      "Recall:  0.8442622950819673\n",
      "Precision:  0.8512396694214877\n",
      "F1:  0.8477366255144033\n",
      "Confusion Matrix: \n",
      " [[109  18]\n",
      " [ 19 103]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(C=0.1, penalty='l2')\n",
    "clf.fit(X_train, y_train.ravel())\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"##### Clf Poly #####\")\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Recall: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"Precision: \", metrics.precision_score(y_test, y_pred))\n",
    "print(\"F1: \", metrics.f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \\n\", metrics.confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, l1_ratio=0.4, penalty='elasticnet', solver='saga')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_final = LogisticRegression(C=0.1, penalty='elasticnet', solver='saga', l1_ratio=0.4)\n",
    "clf.fit(X_one_hot, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n",
      "(1, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [5, 70, 4, 1, 0, 0, 0, 0, 0, 0,\t0,\t1]\n",
    "y_1 = np.array(a)\n",
    "y_1 = y_1.reshape(1,12)\n",
    "\n",
    "clf.predict(y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luismiguel/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function `plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: RocCurveDisplay.from_predictions or RocCurveDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.plot_roc_curve(clf, X_test, y_test)\n",
    "#metrics.plot_roc_curve(clf_2, X_test, y_test)\n",
    "#metrics.plot_roc_curve(clf_3, X_test, y_test)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pos=(y==1)\\nneg=(y==0)\\n\\n# Fit the data to a logistic regression model.\\nclf = sklearn.linear_model.LogisticRegression()\\nclf.fit(X, y)\\n\\n# Retrieve the model parameters.\\nb = clf.intercept_[0]\\nw1, w2, w3, w4, w5 = clf.coef_.T\\n# Calculate the intercept and gradient of the decision boundary.\\nc = -b / w4\\nm = -w2 / w4  # este é o gradiente apenas para a coluna 0 e 1\\n\\n# Plot the data and the classification with the decision boundary.\\nxmin, xmax = -1, 1\\nymin, ymax = -1, 1\\nxd = np.array([xmin, xmax])\\nyd = m * xd + c\\nplt.plot(xd, yd, 'k', lw = 1, ls = '--')\\nplt.fill_between(xd, yd, ymin, color = 'tab:blue', alpha = 0.2)\\nplt.fill_between(xd, yd, ymax, color = 'tab:orange', alpha = 0.2)\\n\\nplt.scatter(X[pos][:,0],X[pos][:,1], s = 8, alpha = 0.5)\\nplt.scatter(X[neg][:,0],X[neg][:,1], s = 8, alpha = 0.5)\\nplt.xlim(xmin, xmax)\\nplt.ylim(ymin, ymax)\\n\\nplt.show()\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''pos=(y==1)\n",
    "neg=(y==0)\n",
    "\n",
    "# Calculate the intercept and gradient of the decision boundary.\n",
    "# este é o gradiente apenas para 2 colunas, se se quiser estudar outras mudar os números do w (os dois a dividir são iguais)\n",
    "c = -b / w3\n",
    "m = -w2 / w3  \n",
    "\n",
    "# Plot the data and the classification with the decision boundary.\n",
    "# Se se mudar as colunas mudar os números aqui também\n",
    "xmin, xmax = min(X[:,2]) - 0.1, max(X[:,2]) +0.1\n",
    "ymin, ymax = min(X[:,3]) - 0.1, max(X[:,3]) +0.1\n",
    "xd = np.array([xmin, xmax])\n",
    "yd = m * xd + c\n",
    "plt.plot(xd, yd, 'k', lw = 1, ls = '--')\n",
    "plt.fill_between(xd, yd, ymin, color = 'tab:blue', alpha = 0.2)\n",
    "plt.fill_between(xd, yd, ymax, color = 'tab:orange', alpha = 0.2)\n",
    "\n",
    "# mudar os numeros aqui também se se for ver outras colunas\n",
    "plt.scatter(X[pos][:,2],X[pos][:,3], alpha = 0.5, c=\"r\",marker=\"+\")\n",
    "plt.scatter(X[neg][:,2],X[neg][:,3], alpha = 0.2, c=\"b\",marker=\"o\")\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(ymin, ymax)\n",
    "\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xx, yy = np.mgrid[-5:5:.01, -5:5:.01]\\ngrid = np.c_[xx.ravel(), yy.ravel()]\\nprobs = clf.predict_proba(grid)[:, 1].reshape(xx.shape)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''xx, yy = np.mgrid[-5:5:.01, -5:5:.01]\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "probs = clf.predict_proba(grid)[:, 1].reshape(xx.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u_vals = np.linspace(-1,1.5,50)\\nv_vals= np.linspace(-1,1.5,50)\\nz=np.zeros((len(u_vals),len(v_vals)))\\nfor i in range(len(u_vals)):\\n    for j in range(len(v_vals)):\\n        z[i,j] = p'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''u_vals = np.linspace(-1,1.5,50)\n",
    "v_vals= np.linspace(-1,1.5,50)\n",
    "z=np.zeros((len(u_vals),len(v_vals)))\n",
    "for i in range(len(u_vals)):\n",
    "    for j in range(len(v_vals)):\n",
    "        z[i,j] = p'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sns.set(style=\"white\")\\n\\ndef map_features(x, degree):\\n    x_old = x.copy()\\n    x = pd.DataFrame({\"intercept\" : [1]*x.shape[0]})\\n    column_index = 1\\n    for i in range(1, degree+1):\\n        for j in range(0, i+1):\\n            x.insert(column_index, str(x_old.columns[1]) + \"^\" + str(i-j) + str(x_old.columns[2]) + \"^\" + str(j), np.multiply(x_old.iloc[:,1]**(i-j), x_old.iloc[:,2]**(j)))\\n            column_index+=1\\n    return x\\n\\ndef normalize_features(x):\\n    global mean_values\\n    global std_values\\n    for column_name in x.columns[1:]:\\n        mean = x[column_name].mean()\\n        std = x[column_name].std()\\n        x[column_name] = (x[column_name] - mean) / std\\n        mean_values[column_name] = mean\\n        std_values[column_name] = std\\n    return x\\n\\ndef sigmoid(z):\\n    return 1/(1+np.exp(-z))\\n\\ndef cost(x, y, theta):\\n    m = x.shape[0]\\n    h_theta = pd.DataFrame(sigmoid(np.dot(x,theta)))\\n    cost = 1/m * ((-np.multiply(y,h_theta.apply(np.log)) - np.multiply(1-y, (1-h_theta).apply(np.log))).sum())\\n    return np.asscalar(cost)\\n\\ndef gradient_descent(x, y, theta):\\n    global cost_values\\n    m = x.shape[0]\\n    iterations = 1000\\n    alpha = 0.03\\n    cost_values = pd.DataFrame({\\'iteration\\' : [0], \\'cost\\' : [cost(x,y,theta)]})\\n\\n    for iteration in range(0,iterations):\\n        theta_old = theta.copy()\\n        theta.iloc[0,0] = theta.iloc[0,0] - (alpha/m) * np.asscalar((sigmoid(np.dot(x,theta_old)) - y).sum())\\n        for i in range(1,theta.shape[0]):\\n            theta.iloc[i,0] = theta.iloc[i,0] - (alpha/m) * np.asscalar(np.multiply((sigmoid(np.dot(x,theta_old)) - y), pd.DataFrame(x.iloc[:,i])).sum())\\n        c = cost(x,y,theta)\\n        cost_values = cost_values.append({\"iteration\" : iteration, \"cost\" : c}, ignore_index=True)\\n\\ndef predict(x):\\n    global theta\\n    probability = np.asscalar(sigmoid(np.dot(x.T,theta)))\\n    return probability\\n    if(probability >= 0.5):\\n        return 1\\n    else:\\n        return 0\\n\\n### Read train data\\n\\n### Create input data\\n#x = train_data.loc[:,\"exam1\":\"exam2\"]\\nx = X\\n### Add intercept column\\nx.insert(0, \"intercept\", 1)\\nmean_values = {}\\nstd_values = {}\\nmapping_degree = 2\\nx = normalize_features(x) #normalize features\\nx = map_features(x, mapping_degree) #map polynomial features\\n#y = pd.DataFrame(train_data.loc[:,\"admit\"])\\ntheta = pd.DataFrame({\"theta\" : [0] * len(x.columns)})\\n\\n### Test cost of initial theta\\n# print(cost(x,y,theta))\\n\\n### Perform Gradient Descent\\ngradient_descent(x, y, theta)\\n# print(theta)\\n# print(\"Cost: \" + str(cost(x,y,theta)))\\n\\n### Plot iteration vs Cost\\nplt.scatter(cost_values[\"iteration\"], cost_values[\"cost\"])\\nplt.show()\\n\\n### Predict an example\\n#student = pd.DataFrame({\"exam1\": [52], \"exam2\":[63]})\\n#student.insert(0, \"intercept\", 1)\\n#normalizing\\n#for column_name in student.columns[1:]:\\n#    student[column_name] = (student[column_name] - mean_values[column_name]) / std_values[column_name]\\n#student = map_features(student, mapping_degree)\\n#print(\"probability of admission: \" + str(predict(student.T)))\\n\\n### Calculate Accuracy\\nacc = 0\\nfor i in range(0,x.shape[0]):\\n    p = predict(pd.DataFrame(x.iloc[i,:]))\\n    actual = y.iloc[i,0]\\n    if(p >= 0.5):\\n        p = 1\\n    else:\\n        p = 0\\n    if(p == actual):\\n        acc+=1\\nprint(\"Accuracy : \" + str((acc/x.shape[0]) * 100))\\n\\n### Plot decision boundary\\nx_min = data[\"exam1\"].min()\\nx_max = data[\"exam1\"].max()\\ny_min = data[\"exam2\"].min()\\ny_max = data[\"exam2\"].max()\\nx_grid, y_grid = np.meshgrid(np.arange(x_min, x_max, 1), np.arange(y_min, y_max, 1))\\nxx = pd.DataFrame(x_grid.ravel(), columns=[\"exam1\"])\\nyy = pd.DataFrame(y_grid.ravel(), columns=[\"exam2\"])\\nz = pd.DataFrame({\"intercept\" : [1]*xx.shape[0]})\\nz[\"exam1\"] = xx\\nz[\"exam2\"] = yy\\nz = normalize_features(z)\\nz = map_features(z,mapping_degree)\\np = z.apply(lambda row: predict(pd.DataFrame(row)), axis=1)\\np = np.array(p.values)\\np = p.reshape(x_grid.shape)\\nplt.scatter(train_data[train_data[\"admit\"] == 0][\"exam1\"], train_data[train_data[\"admit\"] == 0][\"exam2\"],marker=\"o\")\\nplt.scatter(train_data[train_data[\"admit\"] == 1][\"exam1\"], train_data[train_data[\"admit\"] == 1][\"exam2\"],marker=\"x\")\\nplt.contour(x_grid, y_grid, p, levels = [0.5]) #displays only decision boundary\\n# plt.contour(x_grid, y_grid, p, 50, cmap=\"RdBu\") #display a colored contour\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''sns.set(style=\"white\")\n",
    "\n",
    "def map_features(x, degree):\n",
    "    x_old = x.copy()\n",
    "    x = pd.DataFrame({\"intercept\" : [1]*x.shape[0]})\n",
    "    column_index = 1\n",
    "    for i in range(1, degree+1):\n",
    "        for j in range(0, i+1):\n",
    "            x.insert(column_index, str(x_old.columns[1]) + \"^\" + str(i-j) + str(x_old.columns[2]) + \"^\" + str(j), np.multiply(x_old.iloc[:,1]**(i-j), x_old.iloc[:,2]**(j)))\n",
    "            column_index+=1\n",
    "    return x\n",
    "\n",
    "def normalize_features(x):\n",
    "    global mean_values\n",
    "    global std_values\n",
    "    for column_name in x.columns[1:]:\n",
    "        mean = x[column_name].mean()\n",
    "        std = x[column_name].std()\n",
    "        x[column_name] = (x[column_name] - mean) / std\n",
    "        mean_values[column_name] = mean\n",
    "        std_values[column_name] = std\n",
    "    return x\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def cost(x, y, theta):\n",
    "    m = x.shape[0]\n",
    "    h_theta = pd.DataFrame(sigmoid(np.dot(x,theta)))\n",
    "    cost = 1/m * ((-np.multiply(y,h_theta.apply(np.log)) - np.multiply(1-y, (1-h_theta).apply(np.log))).sum())\n",
    "    return np.asscalar(cost)\n",
    "\n",
    "def gradient_descent(x, y, theta):\n",
    "    global cost_values\n",
    "    m = x.shape[0]\n",
    "    iterations = 1000\n",
    "    alpha = 0.03\n",
    "    cost_values = pd.DataFrame({'iteration' : [0], 'cost' : [cost(x,y,theta)]})\n",
    "\n",
    "    for iteration in range(0,iterations):\n",
    "        theta_old = theta.copy()\n",
    "        theta.iloc[0,0] = theta.iloc[0,0] - (alpha/m) * np.asscalar((sigmoid(np.dot(x,theta_old)) - y).sum())\n",
    "        for i in range(1,theta.shape[0]):\n",
    "            theta.iloc[i,0] = theta.iloc[i,0] - (alpha/m) * np.asscalar(np.multiply((sigmoid(np.dot(x,theta_old)) - y), pd.DataFrame(x.iloc[:,i])).sum())\n",
    "        c = cost(x,y,theta)\n",
    "        cost_values = cost_values.append({\"iteration\" : iteration, \"cost\" : c}, ignore_index=True)\n",
    "\n",
    "def predict(x):\n",
    "    global theta\n",
    "    probability = np.asscalar(sigmoid(np.dot(x.T,theta)))\n",
    "    return probability\n",
    "    if(probability >= 0.5):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "### Read train data\n",
    "\n",
    "### Create input data\n",
    "#x = train_data.loc[:,\"exam1\":\"exam2\"]\n",
    "x = X\n",
    "### Add intercept column\n",
    "x.insert(0, \"intercept\", 1)\n",
    "mean_values = {}\n",
    "std_values = {}\n",
    "mapping_degree = 2\n",
    "x = normalize_features(x) #normalize features\n",
    "x = map_features(x, mapping_degree) #map polynomial features\n",
    "#y = pd.DataFrame(train_data.loc[:,\"admit\"])\n",
    "theta = pd.DataFrame({\"theta\" : [0] * len(x.columns)})\n",
    "\n",
    "### Test cost of initial theta\n",
    "# print(cost(x,y,theta))\n",
    "\n",
    "### Perform Gradient Descent\n",
    "gradient_descent(x, y, theta)\n",
    "# print(theta)\n",
    "# print(\"Cost: \" + str(cost(x,y,theta)))\n",
    "\n",
    "### Plot iteration vs Cost\n",
    "plt.scatter(cost_values[\"iteration\"], cost_values[\"cost\"])\n",
    "plt.show()\n",
    "\n",
    "### Predict an example\n",
    "#student = pd.DataFrame({\"exam1\": [52], \"exam2\":[63]})\n",
    "#student.insert(0, \"intercept\", 1)\n",
    "#normalizing\n",
    "#for column_name in student.columns[1:]:\n",
    "#    student[column_name] = (student[column_name] - mean_values[column_name]) / std_values[column_name]\n",
    "#student = map_features(student, mapping_degree)\n",
    "#print(\"probability of admission: \" + str(predict(student.T)))\n",
    "\n",
    "### Calculate Accuracy\n",
    "acc = 0\n",
    "for i in range(0,x.shape[0]):\n",
    "    p = predict(pd.DataFrame(x.iloc[i,:]))\n",
    "    actual = y.iloc[i,0]\n",
    "    if(p >= 0.5):\n",
    "        p = 1\n",
    "    else:\n",
    "        p = 0\n",
    "    if(p == actual):\n",
    "        acc+=1\n",
    "print(\"Accuracy : \" + str((acc/x.shape[0]) * 100))\n",
    "\n",
    "### Plot decision boundary\n",
    "x_min = data[\"exam1\"].min()\n",
    "x_max = data[\"exam1\"].max()\n",
    "y_min = data[\"exam2\"].min()\n",
    "y_max = data[\"exam2\"].max()\n",
    "x_grid, y_grid = np.meshgrid(np.arange(x_min, x_max, 1), np.arange(y_min, y_max, 1))\n",
    "xx = pd.DataFrame(x_grid.ravel(), columns=[\"exam1\"])\n",
    "yy = pd.DataFrame(y_grid.ravel(), columns=[\"exam2\"])\n",
    "z = pd.DataFrame({\"intercept\" : [1]*xx.shape[0]})\n",
    "z[\"exam1\"] = xx\n",
    "z[\"exam2\"] = yy\n",
    "z = normalize_features(z)\n",
    "z = map_features(z,mapping_degree)\n",
    "p = z.apply(lambda row: predict(pd.DataFrame(row)), axis=1)\n",
    "p = np.array(p.values)\n",
    "p = p.reshape(x_grid.shape)\n",
    "plt.scatter(train_data[train_data[\"admit\"] == 0][\"exam1\"], train_data[train_data[\"admit\"] == 0][\"exam2\"],marker=\"o\")\n",
    "plt.scatter(train_data[train_data[\"admit\"] == 1][\"exam1\"], train_data[train_data[\"admit\"] == 1][\"exam2\"],marker=\"x\")\n",
    "plt.contour(x_grid, y_grid, p, levels = [0.5]) #displays only decision boundary\n",
    "# plt.contour(x_grid, y_grid, p, 50, cmap=\"RdBu\") #display a colored contour\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
